{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "for i in range(13670):\n",
    "    site1=\"http://www.cbtc2.ntpu.edu.tw/\"\n",
    "    site2=\"http://www.cbtc2.ntpu.edu.tw/list.php?pg=\"+str(i+1)    \n",
    "    with urllib.request.urlopen(site1) as response:\n",
    "        html = response.read()\n",
    "    with urllib.request.urlopen(site2) as response:\n",
    "        html = response.read()        \n",
    "        outfile=open(r\"C:\\Users\\Ping-tzu 2 Chu A1\\Documents\"+\"\\\\\"+str(i+1)+\".html\", \"bw\")\n",
    "        outfile.write(html)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從維基文庫下載各別標題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "collapsed": true
   },
>>>>>>> 206b8d174ea1cb9566b84eb32dc8239dc769fe7d
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "def getBook(inputTitle):\n",
    "    site = 'https://zh.wikisource.org'\n",
    "    res = requests.get('https://zh.wikisource.org/wiki/'+inputTitle)\n",
    "    soup = BeautifulSoup(res.text, \"html5lib\")\n",
    "    newFile=\"<html><head><title>\"+inputTitle+\"</title></head><body>\"\n",
    "    for link in soup.find_all(\"a\", title=re.compile(inputTitle+\"/\")):\n",
    "        href = link[\"href\"]\n",
    "        title = link[\"title\"][len(inputTitle)+1:]\n",
    "        print(title)\n",
    "        page = BeautifulSoup(requests.get(site+href, \"html5lib\").text)\n",
    "        newFile += \"<div><head>\"+title+\"</head>\"\n",
    "        for p in page.find_all(\"p\"):\n",
    "            newFile += p.prettify()\n",
    "        newFile += \"</div>\"\n",
    "    newFile += \"</body></html>\"\n",
    "    with open(\"d:\\\\temp\\\\\"+inputTitle+\".html\", \"w\", encoding=\"utf-8\") as outFile:\n",
    "        outFile.write(newFile)\n",
    "getBook(\"藝文類聚\")\n",
    "print(\"We're done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "def getBook(title):\n",
    "    site = 'http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98'\n",
    "    requests.get('http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98', auth=HTTPBasicAuth('pingtzuchu', 'kaijun2'))\n",
    "    res = requests.get('http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98')\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    newFile=\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    <?xml-model href=\"http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_all.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\n",
    "    <?xml-model href=\"http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_all.rng\" type=\"application/xml\"\n",
    "        schematypens=\"http://purl.oclc.org/dsdl/schematron\"?>\n",
    "    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
    "      <teiHeader>\n",
    "          <fileDesc>\n",
    "             <titleStmt>\n",
    "                <title>Title</title>\n",
    "             </titleStmt>\n",
    "             <publicationStmt>\n",
    "                <p>Publication Information</p>\n",
    "             </publicationStmt>\n",
    "             <sourceDesc>\n",
    "                <p>Information about the source</p>\n",
    "             </sourceDesc>\n",
    "          </fileDesc>\n",
    "      </teiHeader>\n",
    "      <text>\n",
    "          <body>\"\"\"\n",
    "    for link in soup.find_all(\"a\", title=re.compile(\"墨子/\")):\n",
    "        href = link[\"href\"]\n",
    "        title = link[\"title\"][3:]\n",
    "        page = BeautifulSoup(requests.get(site+href, \"lxml\").text)\n",
    "        newFile += \"<div><head>\"+title+\"</head>\"\n",
    "        for p in page.find_all(\"p\"):\n",
    "            newFile += p.prettify()\n",
    "        newFile += \"</div>\"\n",
    "    newFile += \"</body></text></TEI>\"\n",
    "    with open(\"d:\\\\temp\\\\墨子.xml\", \"w\", encoding=\"utf-8\") as outFile:\n",
    "        outFile.write(newFile)\n",
    "print(\"We're done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "site = 'http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98'\n",
    "requests.get('http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98', auth=HTTPBasicAuth('pingtzuchu', 'kaijun2'))\n",
    "res = requests.get('http://taco.ith.sinica.edu.tw/tdk/%E7%81%8C%E5%9C%92%E5%85%88%E7%94%9F%E6%97%A5%E8%A8%98')\n",
    "print (res.text)\n",
    "input()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "newFile=\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<?xml-model href=\"http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_all.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\n",
    "<?xml-model href=\"http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_all.rng\" type=\"application/xml\"\n",
    "\tschematypens=\"http://purl.oclc.org/dsdl/schematron\"?>\n",
    "<TEI xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
    "  <teiHeader>\n",
    "      <fileDesc>\n",
    "         <titleStmt>\n",
    "            <title>Title</title>\n",
    "         </titleStmt>\n",
    "         <publicationStmt>\n",
    "            <p>Publication Information</p>\n",
    "         </publicationStmt>\n",
    "         <sourceDesc>\n",
    "            <p>Information about the source</p>\n",
    "         </sourceDesc>\n",
    "      </fileDesc>\n",
    "  </teiHeader>\n",
    "  <text>\n",
    "      <body>\"\"\"\n",
    "for link in soup.find_all(\"a\", title=re.compile(\"墨子/\")):\n",
    "    href = link[\"href\"]\n",
    "    title = link[\"title\"][3:]\n",
    "    page = BeautifulSoup(requests.get(site+href, \"lxml\").text)\n",
    "    newFile += \"<div><head>\"+title+\"</head>\"\n",
    "    for p in page.find_all(\"p\"):\n",
    "        newFile += p.prettify()\n",
    "    newFile += \"</div>\"\n",
    "newFile += \"</body></text></TEI>\"\n",
    "with open(\"d:\\\\temp\\\\墨子.xml\", \"w\", encoding=\"utf-8\") as outFile:\n",
    "    outFile.write(newFile)\n",
    "print(\"We're done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
   "metadata": {},
>>>>>>> 206b8d174ea1cb9566b84eb32dc8239dc769fe7d
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re, time\n",
    "from bs4 import BeautifulSoup\n",
<<<<<<< HEAD
    "driver = webdriver.Firefox(executable_path=r\"D:\\drivers\\geckodriver.exe\")\n",
    "firstPage=driver.get(\"http://taco.ith.sinica.edu.tw/tdk/index.php?title=特殊:用戶登錄\")\n",
    "name = driver.find_element_by_id(\"wpName1\").send_keys(\"pingtzuchu\")\n",
    "password = driver.find_element_by_id(\"wpPassword1\").send_keys(\"kaijun2\")\n",
    "elem = driver.find_element_by_id(\"wpRemember\")\n",
    "time.sleep(5)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "time.sleep(10)\n",
    "base_uri =\"http://taco.ith.sinica.edu.tw\"\n",
    "diary=\"http://taco.ith.sinica.edu.tw/tdk/水竹居主人日記\"\n",
    "newFile=\"<人>\"\n",
    "driver.get(diary)\n",
    "WebDriverWait(driver, 300).until(\n",
    "    EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    ")\n",
    "pageSource=driver.page_source\n",
    "soup = BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "newFile += \"<page>\"+soup.prettify()+\"</page>\\n\"\n",
    "fileNum = 1\n",
    "controlNum = 15\n",
    "for yearLink in soup.find_all(\"a\", title=re.compile(\"水竹居主人日記/\")):\n",
    "    if fileNum > controlNum:\n",
    "        href = yearLink[\"href\"]\n",
    "        newFile += \"<年><page><title>\"+yearLink[\"title\"]+\"</title>\"\n",
    "        driver.get(base_uri+href)\n",
    "        WebDriverWait(driver, 300).until(\n",
    "            EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "        )\n",
    "        pageSource=driver.page_source\n",
    "        yearsoup = BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "        newFile += yearsoup.prettify()+\"</page>\\n\"\n",
    "        for monthLink in yearsoup.find_all(\"a\", title=re.compile(\"水竹居主人日記/\")):\n",
    "            href = monthLink['href']\n",
    "            newFile += \"<月><page><title>\"+monthLink[\"title\"]+\"</title>\"\n",
    "            driver.get(base_uri+href)\n",
    "            WebDriverWait(driver, 300).until(\n",
    "                EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "            )\n",
    "            pageSource=driver.page_source\n",
    "            monthsoup=BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "            newFile += monthsoup.prettify()+\"</page>\\n\"\n",
    "            for dayLink in monthsoup.find_all(\"a\", title=re.compile(\"水竹居主人日記/\")):\n",
    "                href = dayLink[\"href\"]\n",
    "                newFile += \"<日><page><title>\"+dayLink[\"title\"]+\"</title>\"\n",
    "                driver.get(base_uri+href)\n",
    "                WebDriverWait(driver, 300).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "                )\n",
    "                pageSource=driver.page_source\n",
    "                dayPage=BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "                newFile += dayPage.prettify()+\"</page>\\n</日>\"\n",
    "            newFile += \"</月>\"\n",
    "        newFile += \"</年>\"\n",
    "        with open(\"d:\\\\temp\\\\水竹居主人日記_\"+\"0\"*(2-len(str(fileNum)))+str(fileNum)+\".xml\", \"w\", encoding=\"utf8\") as outFile:\n",
    "            outFile.write(newFile+\"</人>\")\n",
    "        newFile=\"<人>\"\n",
    "    print(fileNum)\n",
    "    fileNum += 1\n",
    "print(\"We're done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re, time\n",
    "from bs4 import BeautifulSoup\n",
    "driver = webdriver.Firefox(executable_path=r\"D:\\drivers\\geckodriver.exe\")\n",
    "firstPage=driver.get(\"http://taco.ith.sinica.edu.tw/tdk/index.php?title=特殊:用戶登錄\")\n",
    "emptyTest=input()\n",
    "time.sleep(10)\n",
    "base_uri =\"http://taco.ith.sinica.edu.tw\"\n",
    "diary=\"http://taco.ith.sinica.edu.tw/tdk/水竹居主人日記\"\n",
    "newFile=\"<人>\"\n",
    "driver.get(diary)\n",
    "WebDriverWait(driver, 300).until(\n",
    "    EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    ")\n",
    "pageSource=driver.page_source\n",
    "soup = BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "newFile += \"<page>\"+soup.prettify()+\"</page>\\n\"\n",
    "fileNum = 1\n",
    "controlNum = 27\n",
    "for yearLink in soup.find_all(\"a\", title=re.compile(\"水竹居主人日記/\")):\n",
    "    if fileNum > controlNum:\n",
    "        href = yearLink[\"href\"]\n",
    "        newFile += \"<年><page><title>\"+yearLink[\"title\"]+\"</title>\"\n",
    "        driver.get(base_uri+href)\n",
    "        WebDriverWait(driver, 300).until(\n",
    "            EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "        )\n",
    "        pageSource=driver.page_source\n",
    "        yearsoup = BeautifulSoup(pageSource).find(id=\"mw-content-text\")\n",
    "        newFile += yearsoup.prettify()+\"</page>\\n\"\n",
    "        for monthLink in yearsoup.find_all(\"a\", title=re.compile(\"水竹居主人日記/\")):\n",
    "            href = monthLink['href']\n",
    "            newFile += \"<月><page><title>\"+monthLink[\"title\"]+\"</title>\"\n",
=======
    "driver = webdriver.Chrome(executable_path=r\"D:\\drivers\\chromedriver.exe\")\n",
    "def get_diary(diary):\n",
    "    firstPage=driver.get(\"http://taco.ith.sinica.edu.tw/tdk/index.php?title=特殊:用戶登錄\")\n",
    "    name = driver.find_element_by_id(\"wpName1\").send_keys(\"pingtzuchu\")\n",
    "    password = driver.find_element_by_id(\"wpPassword1\").send_keys(\"kaijun2\")\n",
    "    elem = driver.find_element_by_id(\"wpRemember\")\n",
    "    time.sleep(3)\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)\n",
    "    base_uri =\"http://taco.ith.sinica.edu.tw\"\n",
    "    diary=\"http://taco.ith.sinica.edu.tw/tdk/\"+diary\n",
    "    newFile=\"<人>\"\n",
    "    driver.get(diary)\n",
    "    WebDriverWait(driver, 300).until(\n",
    "        EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "    )\n",
    "    pageSource=driver.page_source\n",
    "    soup = BeautifulSoup(pageSource, \"xml\").find(id=\"mw-content-text\")\n",
    "    newFile += \"<page>\"+soup.prettify()+\"</page>\\n\"\n",
    "    fileNum = 1\n",
    "    controlNum = 0\n",
    "    for yearLink in soup.find_all(\"a\", title=re.compile(diary+\"/\")):\n",
    "        if fileNum > controlNum:\n",
    "            href = yearLink[\"href\"]\n",
    "            newFile += \"<年><page><title>\"+yearLink[\"title\"]+\"</title>\"\n",
>>>>>>> 206b8d174ea1cb9566b84eb32dc8239dc769fe7d
    "            driver.get(base_uri+href)\n",
    "            WebDriverWait(driver, 300).until(\n",
    "                EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "            )\n",
    "            pageSource=driver.page_source\n",
    "            yearsoup = BeautifulSoup(pageSource, \"xml\").find(id=\"mw-content-text\")\n",
    "            newFile += yearsoup.prettify()+\"</page>\\n\"\n",
    "            for monthLink in yearsoup.find_all(\"a\", title=re.compile(\"diary\"+\"/\")):\n",
    "                href = monthLink['href']\n",
    "                newFile += \"<月><page><title>\"+monthLink[\"title\"]+\"</title>\"\n",
    "                driver.get(base_uri+href)\n",
    "                WebDriverWait(driver, 300).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "                )\n",
    "                pageSource=driver.page_source\n",
    "                monthsoup=BeautifulSoup(pageSource, \"xml\").find(id=\"mw-content-text\")\n",
    "                newFile += monthsoup.prettify()+\"</page>\\n\"\n",
    "                for dayLink in monthsoup.find_all(\"a\", title=re.compile(diary+\"/\")):\n",
    "                    href = dayLink[\"href\"]\n",
    "                    newFile += \"<日><page><title>\"+dayLink[\"title\"]+\"</title>\"\n",
    "                    driver.get(base_uri+href)\n",
    "                    WebDriverWait(driver, 300).until(\n",
    "                        EC.presence_of_element_located((By.ID, \"mw-content-text\"))\n",
    "                    )\n",
    "                    pageSource=driver.page_source\n",
    "                    dayPage=BeautifulSoup(pageSource, \"xml\").find(id=\"mw-content-text\")\n",
    "                    newFile += dayPage.prettify()+\"</page>\\n</日>\"\n",
    "                newFile += \"</月>\"\n",
    "            newFile += \"</年>\"\n",
    "            with open(\"d:\\\\temp\\\\\"+diary+\"_0\"*(2-len(str(fileNum)))+str(fileNum)+\".xml\", \"w\", encoding=\"utf8\") as outFile:\n",
    "                outFile.write(newFile+\"</人>\")\n",
    "            newFile=\"<人>\"\n",
    "        print(fileNum)\n",
    "        fileNum += 1\n",
    "    print(\"We're done.\")\n",
    "get_diary(\"吳嵩慶日記\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = subprocess.check_output\n",
    "with open(\"d:\\\\temp\\\\\"+\"太平御覽.xml\", \"w\", encoding=\"utf-8\") as outFile:\n",
    "        outFile.write(sys.stdout)\n",
    "print(sys.stdout:)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.3"
=======
   "version": "3.6.2"
>>>>>>> 206b8d174ea1cb9566b84eb32dc8239dc769fe7d
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
