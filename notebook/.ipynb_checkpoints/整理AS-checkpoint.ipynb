{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＃整理AS：用字串找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "from bs4 import BeautifulSoup\n",
    "filepath = r\"F:\\AS\\四明叢書\"\n",
    "currentLevel=0\n",
    "missingFiles=[]\n",
    "initial = 1\n",
    "for fileNum in range(16442, 28491):\n",
    "    try:\n",
    "        with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\", encoding=\"utf8\") as infile:\n",
    "            soup = BeautifulSoup(infile.read(), \"html\")\n",
    "            theHead = soup.find(string=re.compile(r\"叢書／叢書／四明叢書／[^\\(]+\\(\"))\n",
    "            if len(theHead) > 0:\n",
    "                theHead = theHead[:(theHead.find(\"(\"))]\n",
    "                headLen = len(theHead.split(\"／\"))\n",
    "                theSpan = soup.find(\"span\", id=\"fontstyle\")\n",
    "                try:\n",
    "                    theBegin = str(theSpan.div.string)[:5]\n",
    "                except:\n",
    "                    theBegin = \"\"\n",
    "                if (initial == 1) or (headLen == 5): #如果是起始文件，設定好起始值後離開\n",
    "                    if initial == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        currentDiv.append(spanPrev)\n",
    "                        with open(filepath+\"\\\\\" + headPrev.split(\"／\")[4]+\".html\",\n",
    "                                  \"w\", encoding=\"utf8\") as outfile:\n",
    "                            outfile.write(finalXML.prettify())\n",
    "                        print(headPrev.split(\"／\")[3])\n",
    "                        print(fileNum)\n",
    "                    headPrev = theHead\n",
    "                    spanPrev = theSpan\n",
    "                    beginPrev = theBegin\n",
    "                    finalXML = BeautifulSoup(\"<div/>\", \"html\")\n",
    "                    currentDiv = finalXML.div\n",
    "                    newHead = finalXML.new_tag(\"head\")\n",
    "                    currentDiv.append(newHead)\n",
    "                    newHead.string=theHead.split(\"／\")[3]\n",
    "                    initial = 0\n",
    "                else:\n",
    "                    if theHead == headPrev: #如果兩頁標題一樣，跳到下一頁\n",
    "                        pass\n",
    "                    else:\n",
    "                        if headPrev in theHead: #如果前頁標題包含在下一頁\n",
    "                            #檢查頁前5字是否不一樣，不一樣的話也加入內容\n",
    "                            if not theBegin == beginPrev: \n",
    "                                currentDiv.append(spanPrev)\n",
    "                        else: #不包含在下一頁，儲存舊的標題內容，移動Level\n",
    "                            currentDiv.append(spanPrev)\n",
    "                            for i in range(len(headPrev.split(\"／\"))-headLen+1):\n",
    "                                currentDiv = currentDiv.parent\n",
    "                        spanPrev = theSpan\n",
    "                        headTag = finalXML.new_tag(\"head\")\n",
    "                        newDiv = finalXML.new_tag(\"div\")\n",
    "                        currentDiv.append(newDiv)\n",
    "                        currentDiv = newDiv\n",
    "                        currentDiv.append(headTag)\n",
    "                        headTag.string = theHead\n",
    "                        headPrev = theHead\n",
    "                        beginPrev = theBegin\n",
    "            else:\n",
    "                missingFiles.append(fileNum)\n",
    "    except:\n",
    "        missingFiles.append(fileNum)\n",
    "try:\n",
    "    currentDiv.append(spanPrev)\n",
    "except:\n",
    "    pass\n",
    "with open(filepath+\"\\\\\" + headPrev.split(\"／\")[4]+\".html\",\n",
    "         \"w\", encoding=\"utf8\") as outfile:\n",
    "    outfile.write(finalXML.prettify())\n",
    "print(missingFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "filepath = r\"D:\\AS\\漢籍十三經注疏\"\n",
    "newDoc=\"<div>\"\n",
    "headTag = re.compile(r\"<head>(.*)</head>\", re.S)\n",
    "headPrev2 = [\"\",\"\",\"\",\"\"]\n",
    "for fileNum in range(0, 2754):\n",
    "    with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\", encoding=\"utf8\") as infile:\n",
    "        text = infile.read()\n",
    "        match = re.search(headTag, text)\n",
    "        if (match.group(0) is None) or (match.group(0).find(\"／\")==-1):\n",
    "            pass\n",
    "        else:\n",
    "            headNow = match.group(1).split(\"(\")[0]\n",
    "            headNow2 = headNow.split(\"／\")\n",
    "            if ((not headNow2[3] == headPrev2[3]) and (headPrev2[3]!=\"\")) or (fileNum == 2753):\n",
    "                if fileNum == 2753:\n",
    "                    newDoc += text+\"</div>\"\n",
    "                else:\n",
    "                    newDoc+= \"</div>\"\n",
    "                with open(r\"D:\\AS\"+\"\\\\\"+headPrev2[3]+\".xml\", \"w\", \n",
    "                          encoding = \"utf8\") as outfile:\n",
    "                    outfile.write(newDoc)\n",
    "                    print(headPrev2[3]+\"：\" + \"LastFile: \"+str(fileNum))\n",
    "                    newDoc=\"<div>\"\n",
    "                    headPrev2=[\"\",\"\",\"\",\"\"]\n",
    "            else:\n",
    "                newDoc += text\n",
    "            headPrev2 = headNow2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "單本書 div head 結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from bs4 import BeautifulSoup\n",
    "filepath = r\"F:\\AS\\incoming\"\n",
    "savePath = r\"F:\\AS\"\n",
    "currentLevel=0\n",
    "missingFiles=[]\n",
    "initial = 1\n",
    "for fileNum in range(3000, 12822):\n",
    "    try:\n",
    "        with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\", encoding=\"utf8\") as infile:\n",
    "            soup = BeautifulSoup(infile.read(),\"xml\")\n",
    "    except:\n",
    "        with open(savePath+\"\\\\\" + \"春秋辨疑.xml\", \"w\", encoding=\"utf8\") as outfile:\n",
    "            outfile.write(finalXML.prettify())\n",
    "            print(missingFiles)\n",
    "            print(theHead)\n",
    "        print(fileNum)\n",
    "        input()\n",
    "        missingFiles.append(fileNum)\n",
    "    theHead = str(soup.head.string)\n",
    "    headLen = len(theHead.split(\"／\"))\n",
    "    theSpan = soup.span\n",
    "    try:\n",
    "        theBegin = str(theSpan.div.string)[:5]\n",
    "    except:\n",
    "        theBegin = \"\"\n",
    "    if initial == 1: #如果是起始文件，設定好起始值後離開\n",
    "        headPrev = theHead\n",
    "        spanPrev = theSpan\n",
    "        beginPrev = theBegin\n",
    "        finalXML = BeautifulSoup(\"<div/>\", \"xml\")\n",
    "        currentDiv = finalXML.div\n",
    "        newHead = finalXML.new_tag(\"head\")\n",
    "        currentDiv.append(newHead)\n",
    "        newHead.string=theHead.split(\"／\")[2]\n",
    "        initial = 0\n",
    "    else:\n",
    "        if theHead == headPrev: #如果兩頁標題一樣，跳到下一頁\n",
    "            pass\n",
    "        else:\n",
    "            if headPrev in theHead: #如果前頁標題包含在下一頁\n",
    "                #檢查頁前5字是否不一樣，不一樣的話也加入內容\n",
    "                if not theBegin == beginPrev: \n",
    "                    currentDiv.append(spanPrev)\n",
    "            else: #不包含在下一頁，儲存舊的標題內容，移動Level\n",
    "                currentDiv.append(spanPrev)\n",
    "                for i in range(len(headPrev.split(\"／\"))-headLen+1):\n",
    "                    currentDiv = currentDiv.parent\n",
    "            spanPrev = theSpan\n",
    "            headTag = finalXML.new_tag(\"head\")\n",
    "            newDiv = finalXML.new_tag(\"div\")\n",
    "            currentDiv.append(newDiv)\n",
    "            currentDiv = newDiv\n",
    "            currentDiv.append(headTag)\n",
    "            headTag.string = theHead\n",
    "            headPrev = theHead\n",
    "            beginPrev = theBegin\n",
    "try:\n",
    "    currentDiv.append(spanPrev)\n",
    "except:\n",
    "    pass\n",
    "with open(savePath+\"\\\\\" + \"春秋辨疑.xml\",\n",
    "         \"w\", encoding=\"utf8\") as outfile:\n",
    "    outfile.write(finalXML.prettify())\n",
    "print(missingFiles)\n",
    "print(theHead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "整理多個文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from bs4 import BeautifulSoup\n",
    "filepath = r\"F:\\AS\\incoming\"\n",
    "savePath = r:\"F:\\AS\"\n",
    "currentLevel=0\n",
    "missingFiles=[]\n",
    "initial = 1\n",
    "for fileNum in range(3000, 12822):\n",
    "    try:\n",
    "        with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\", encoding=\"utf8\") as infile:\n",
    "            soup = BeautifulSoup(infile.read(), \"xml\")\n",
    "            theHead = str(soup.head.string)\n",
    "            headLen = len(theHead.split(\"／\"))\n",
    "            theSpan = soup.find(\"span\", id=\"fontstyle\")\n",
    "            try:\n",
    "                theBegin = str(theSpan.div.string)[:5]\n",
    "            except:\n",
    "                theBegin = \"\"\n",
    "            if (initial == 1) or (headLen == 4): #如果是起始文件，設定好起始值後離開\n",
    "                if initial == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    currentDiv.append(spanPrev)\n",
    "                    with open(filepath+\"\\\\\" + headPrev.split(\"／\")[3]+\".xml\",\n",
    "                              \"w\", encoding=\"utf8\") as outfile:\n",
    "                        outfile.write(finalXML.prettify())\n",
    "                        print(headPrev.split(\"／\")[3])\n",
    "                headPrev = theHead\n",
    "                spanPrev = theSpan\n",
    "                beginPrev = theBegin\n",
    "                finalXML = BeautifulSoup(\"<div/>\", \"xml\")\n",
    "                currentDiv = finalXML.div\n",
    "                newHead = finalXML.new_tag(\"head\")\n",
    "                currentDiv.append(newHead)\n",
    "                newHead.string=theHead.split(\"／\")[3]\n",
    "                initial = 0\n",
    "            else:\n",
    "                if theHead == headPrev: #如果兩頁標題一樣，跳到下一頁\n",
    "                    pass\n",
    "                else:\n",
    "                    if headPrev in theHead: #如果前頁標題包含在下一頁\n",
    "                        #檢查頁前5字是否不一樣，不一樣的話也加入內容\n",
    "                        if not theBegin == beginPrev: \n",
    "                            currentDiv.append(spanPrev)\n",
    "                    else: #不包含在下一頁，儲存舊的標題內容，移動Level\n",
    "                        currentDiv.append(spanPrev)\n",
    "                        for i in range(len(headPrev.split(\"／\"))-headLen+1):\n",
    "                            currentDiv = currentDiv.parent\n",
    "                    spanPrev = theSpan\n",
    "                    headTag = finalXML.new_tag(\"head\")\n",
    "                    newDiv = finalXML.new_tag(\"div\")\n",
    "                    currentDiv.append(newDiv)\n",
    "                    currentDiv = newDiv\n",
    "                    currentDiv.append(headTag)\n",
    "                    headTag.string = theHead\n",
    "                    headPrev = theHead\n",
    "                    beginPrev = theBegin\n",
    "    except:\n",
    "        missingFiles.append(fileNum)\n",
    "    print(fileNum)\n",
    "    print(headPrev.split(\"／\")[3])\n",
    "try:\n",
    "    currentDiv.append(spanPrev)\n",
    "except:\n",
    "    pass\n",
    "with open(filepath+\"\\\\\" + headPrev.split(\"／\")[3]+\".xml\",\n",
    "         \"w\", encoding=\"utf8\") as outfile:\n",
    "    outfile.write(finalXML.prettify())\n",
    "print(missingFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "filepath = r\"F:\\AS\\incoming\"\n",
    "missingFiles=[]\n",
    "cannotFind=[]\n",
    "for fileNum in range(0, 2131):\n",
    "    try:\n",
    "        with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\",\n",
    "                  encoding=\"utf8\") as infile:\n",
    "            if \"經／十三經／重刊宋本十三經注疏附校勘記／\" in infile.read():\n",
    "                pass\n",
    "            else:\n",
    "                cannotFind.append(fileNum)\n",
    "    except:\n",
    "        missingFiles.append(fileNum)\n",
    "print(missingFiles)\n",
    "print(cannotFind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "以下 div head結構(單本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from bs4 import BeautifulSoup\n",
    "filepath = r\"F:\\AS\\incoming\"\n",
    "savePath = r\"F:\\AS\"\n",
    "currentLevel=0\n",
    "missingFiles=[]\n",
    "initial = 1\n",
    "fileNumber = 1\n",
    "for fileNum in range(1, 125):\n",
    "    try:\n",
    "        with open(filepath+\"\\\\\"+str(fileNum).strip()+\".html\", \"r\", encoding=\"utf8\") as infile:\n",
    "            soup = BeautifulSoup(infile.read(), \"html5lib\")\n",
    "            theHead = str(soup.head.string)\n",
    "            theHead = theHead\n",
    "            if len(theHead) > 0:\n",
    "                headLen = len(theHead.split(\"／\"))\n",
    "                theSpan = soup.find(\"span\", id=\"fontstyle\")\n",
    "                try:\n",
    "                    theBegin = str(theSpan.div.string)[:5]\n",
    "                except:\n",
    "                    theBegin = \"\"\n",
    "                if (initial == 1) or (headLen == 4): #如果是起始文件，設定好起始值後離開\n",
    "                    if initial == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        currentDiv.append(spanPrev)\n",
    "                        with open(filepath+\"\\\\\" + \"0\"*(3-len(str(fileNumber).strip()))+\n",
    "                                  str(fileNumber).strip()+\".html\", \"w\", \n",
    "                                  encoding=\"utf8\") as outfile:\n",
    "                            outfile.write(finalXML.prettify())\n",
    "                            print(\"0\"*(3-len(str(fileNumber).strip())))\n",
    "                    headPrev = theHead\n",
    "                    spanPrev = theSpan\n",
    "                    beginPrev = theBegin\n",
    "                    finalXML = BeautifulSoup(\"<div/>\", \"html5lib\")\n",
    "                    currentDiv = finalXML.div\n",
    "                    newHead = finalXML.new_tag(\"h2\")\n",
    "                    currentDiv.append(newHead)\n",
    "                    try:\n",
    "                        currentDiv.head.string=theHead\n",
    "                    except:\n",
    "                        pass\n",
    "                    initial = 0\n",
    "                else:\n",
    "                    if theHead == headPrev: #如果兩頁標題一樣，跳到下一頁\n",
    "                        pass\n",
    "                    else:\n",
    "                        if headPrev in theHead: #如果前頁標題包含在下一頁\n",
    "                            #檢查頁前5字是否不一樣，不一樣的話也加入內容\n",
    "                            if not theBegin == beginPrev: \n",
    "                                currentDiv.append(spanPrev)\n",
    "                        else: #不包含在下一頁，儲存舊的標題內容，移動Level\n",
    "                            currentDiv.append(spanPrev)\n",
    "                            for i in range(len(headPrev.split(\"／\"))-headLen+1):\n",
    "                                currentDiv = currentDiv.parent\n",
    "                        spanPrev = theSpan\n",
    "                        headTag = finalXML.new_tag(\"head\")\n",
    "                        newDiv = finalXML.new_tag(\"div\")\n",
    "                        currentDiv.append(newDiv)\n",
    "                        currentDiv = newDiv\n",
    "                        currentDiv.append(headTag)\n",
    "                        headTag.string = theHead\n",
    "                        headPrev = theHead\n",
    "                        beginPrev = theBegin\n",
    "            else:\n",
    "                missingFiles.append(fileNum)\n",
    "    except:\n",
    "        missingFiles.append(fileNum)\n",
    "try:\n",
    "    currentDiv.append(spanPrev)\n",
    "except:\n",
    "    pass\n",
    "with open(savePath+\"\\\\\" + \"0\"*(3-len(str(fileNumber).strip()))+str(fileNumber).strip()+\".html\",\n",
    "         \"w\", encoding=\"utf8\") as outfile:\n",
    "    outfile.write(finalXML.prettify())\n",
    "print(missingFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "rootDir = r\"F:\\AS\\incoming\"\n",
    "for i in range(2130):\n",
    "    if os.path.exists(rootDir+\"\\\\\"+str(i).strip()+\".html\"):\n",
    "        pass\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
